# 카프카 설정

## 1. 적재 정책

> 카프카에 어떤 데이터를 어떤 기준으로 적재할지 적재 정책을 결정해야 한다. 적재 정책에 따라 파이프라인의 운영 난이도가 달라진다.


## 2. 데이터 포맷

> VO(Value Object)
> - 보편적이고 편리
> - 프로듀서와 컨슈머에 모두 같은 VO 타입을 선언해야 하는 불편함
> - 스키마가 변경될 경우 비용이 큼.
> - 직렬화된 객체는 kafka-console-consumer 명령어를 통해 내부 데이터를 확인할 수 없음(디버깅 어려움)

> JSON
> - 스키마 변화에 유연함
> - kafka-console-consumer 명령어로 내부 데이터를 볼 수 있음 (디버깅 용이)
> - 프로듀서와 컨슈머는 기본 직렬화인 String 을 사용할 수 있음 (ByteArray로도 가능)


## 3. 프로듀서

### ack

> 프로듀서가 전송한 데이터가 브로커들에 정상적으로 저장되었는지 전송 성공 여부를 확인하는 데 사용하는 옵션 (p208)
> 
- 1 : 리더 파티션에만 저장되면 성공으로 판단
- 0 : 프로듀서가 전송한 즉시 브로커에 데이터 저장 여부와 상관 없이 성공으로 판단
- -1(all) : min.insync.replicas 개수에 해당하는 리더 파티션과 팔로워 파티션 모두에 데이터가 저장되면 성공으로 판단

### 최소 동기화 리플리카 설정(min.insync.replicas)

> 프로듀서가 리더 파티션과 팔로워 파티션에 데이터가 적재되었는지 확인하기 위한 최소 ISR 그룹의 파티션 개수 (p211)
> 
- ack = 1 인 경우 해당 설정은 무시하고 리더 파티션에 지속 적재하므로, 설정할 필요가 없다. (min.insync.replicas = 1인 상황)
- ack = all 인 경우 min.insync.replicas = 2 이상인 값이어야 정상적으로 동작한다.
- 운영 환경에서는 acks=all, replication.factor=3, min.insync.replicas=2 가 일반적이다.

### 파티셔너 설정

> 파티셔너를 활용하면 메시지 키 또는 메시지 값을 기반으로 어떤 파티션으로 전달될지 결정하는 로직을 적용할 수 있다.
> 
- 특별한 파티션 분류 방법이 필요없다면 기본 설정(`UniformStickyPartitioner`) 사용

### 재시도 설정(retries)

> 프로듀서가 브로커로부터 에러를 받고 난 뒤 재전송을 시도하는 횟수
> 
- 기본값: 2147483647 (Integer.MAX_VALUE)
- 프로듀서가 전송을 재시도할 경우 데이터 중복 및 순서가 변경될 수 있다.

### 압축 옵션

> 프로듀서의 압축은 gzip, snappy, lz4, zstd 중 하나를 선택할 수 있고, 압축을 하면 클러스터에 적재되는 데이터의 총 용량을 줄이고 네트워크 사용량을 줄이는 데 효과적이다. 하지만 프로듀서와 컨슈머의 CPU와 메모리 사용량이 늘어난다.
> 

## 4. 토픽과 파티션

### 이름설정

토픽 작명 템플릿

- `<환경>.<팀-명>.<애플리케이션-명>.<메시지-타입>`
    - Ex) prod.markerting-team.sms-platform.json
- `<프로젝트-명>.<서비스-명>.<환경>.<이벤트-명>`
    - Ex) commerce.payment.prd.notification
- `<환경>.<서비스-명>.<JIRA-명>.<메시지-타입>`
    - Ex) dev.email-sender.jira-1234.email-vo-custom
- `<카프카-클러스터-명>.<환경>.<서비스-명>.<메시지-타입>`
    - Ex) aws-kafka.live.marketing-platform.json

토픽 이름 제약 조건(p73)

- 빈 문자열은 사용할 수 없다.
- 마침표 하나(.) 또는 마침표 둘(..) 로만은 생성할 수 없다.
- 길이는 249자 미만
- 영어 대소문자, 숫자(0~9), 마침표(.), 언더바(_), 하이픈(-) 조합으로만 생성할 수 있다.
- 카프카 내부 로직 관리 목적으로 사용되는 2개 토픽(__consumer_offsets, __transaction_state)과 동일한 이름은 불가능
- 카프카 내부 로직상 마침표(.)와 언더바(_)를 동시에 사용할 수 없다. (사용할 수는 있지만 이슈가 발생할 수 있어 경고 문구가 발생)
- to.pic 토픽 이름이 생성된 이후에는 to_pic 이름은 사용할 수 없다. (반대의 경우도 생성할 수 없음)

### 파티션 개수

> 파티션 개수 고려사항(p198)
- 데이터 처리량
- 메시지 키 사용 여부
- 브로커, 컨슈머 영향도
> 
- 데이터 처리량
    - 참고 공식 : 프로듀서 전송 데이터량 < 컨슈머 데이터 처리량  * 파티션 개수
- 메시지 키 사용 여부
    - 메시지 키는 데이터의 순서와 연관
    - 메시지 키를 사용하는 상태에서 파티션 개수를 변화시키면 순서를 보장받지 못한다.
        - 파티션 개수를 변화하고도 순서를 보장하려면 커스텀한 로직이 필요
- 브로커, 컨슈머 영향도
    - 카프카의 파티션은 각 프로커의 파일 시스템을 사용하고 있는데, 운영체제마다 프로세스당 열 수 있는 파일 개수를 제한하고 있다.
    - 컨슈머가 많아져서 파티션 개수가 많아진다면, 파일 개수 제한으로 브로커를 늘려야 할 수도 있다.

### 메시지 키 사용 여부

### 복제 개수 (replication factor)

> 복제 개수가 높으면 높을수록 데이터의 복구 확률이 높아진다.
> 
- 브로커 복제 개수는 최소 2 이상이어야 하며, 운영 환경은 3 이상이 기본이다.

### 토픽 정리 정책(cleanup.policy)

p201

## 5. 컨슈머

- 그룹이름: 컨슈머의 목적을 구분할 수 있는 이름으로 명시 (p96)
    - Ex) 이메일 발송 처리 애플리케이션인 경우, email-application-group
- 커밋 (p102)
    - 비명시적 커밋 = 오토 커밋
        - 편리하지만, 데이터가 중복 또는 유실될 수 있다.
    - 명시적 커밋 = `commitSync()` 또는 `commitAsyc()` 메서드를 명시적으로 호출

## 수정이력 카프카 설정

파이프라인 정책

- 데이터가 유실 및 중복이 되면 안된다.
- 안정적으로 끊임없이 적재되어야 한다.
- 갑작스럽게 발생하는 많은 데이터양을 허용해야 한다.

데이터 포맷

- JSON
- String 직렬화/역직렬화

프로듀서 옵션 설정

- dev 환경
    - ack: all
    - min.insync.replicas = 2
    - enable.idempotence = true

토픽

- 토픽 이름: dev.common.change-history.json
    - `<환경>.<도메인명>.<서비스명>.<메시지-타입>`
        - dev.acquisition.알림센터.json
        - dev.acquisition.통지수단.json
- 그룹 이름: mongodb-load-group
- 파티션 개수
    - dev 환경: 2개
- 복제 개수
    - dev 환경: 2개

컨슈머 옵션 설정

- dev 환경
    - auto-offset-reset: earliest
    - max-poll-records: 10000
    - enable-auto-commit: false
    - 

카프카 설정

- 운영환경에서는 브로커 개수가 3대 이상이어야 한다.
- 의미있는 토픽 이름 사용 (p74) / 의미있는 컨슈머 그룹이름 사용(p96)
- 프로듀서 옵션 (p88)
    - acks (p208)
        - 운영 환경에서는 acks=all, replication.factor=3, min.insync.replicas=2 가 일반적이다.
            - acks=all 옵션은 min.insync.replicas 개수와 연관이 있다. 리더와 팔로우가 서로 복제하는지 설정하는 값이 2 이상이어야 all이 정상적으로 동작한다.
    - 멱등성 : 동일한 데이터를 브로커에 단 한 번만 저장
        - enable.idempotence = true
            - 위 옵션이 참이면 강제로 다음 옵션도 설정됨.
                - retries = Integer.MAX_VALUE
                - acks = all
        - seq 순서가 맞지 않아도 OutOfOrder... 예외가 발생함. → 순서가 중요하지 않으면 이 예외처리 무시해도 될듯함.
        - 프로듀서 애플리케이션이 정상 동작할 때만 멱등성이 유지된다. (애플리케이션이 종료되면 PID가 초기화되므로 중복으로 보낼 가능성도 있다.)
- 컨슈머 오토 커밋 개요 (p103)
- 컨슈머 옵션 (p104)
- 토픽 삭제 정책 (p201)
    - 토픽 내부 데이터는 이미 몽고디비에 저장하므로, 일정시간이 지나면 삭제하는 것이 좋겠다.
- 컨슈머 배포 정책 (p240)
    - 파티션과 컨슈머 개수에 따라 배포 정책을 달리하는 것이 좋음.

## 참고자료

최원영님이 쓰신 아파치 카프카